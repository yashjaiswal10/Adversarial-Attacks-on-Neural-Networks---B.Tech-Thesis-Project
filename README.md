# AdversarialAttacks

BTP Thesis Project - Adversarial Attacks on Neural Networks

Our team developed the model under the Mentorship of Dr.Saumya Bhadauria and Dr.Yash Daultani to create an adversarial attack on the existing
deep learning models by modifying input image such that it
will be classified incorrectly.

We also Suggested the defenses against these adversarial attacks
inorder to make the model robust so that it can classify perturbed
images correctly.

Here are some screenshots of our model :
![Screenshot (166)](https://user-images.githubusercontent.com/39501945/77751149-2727cf80-704b-11ea-9675-e00336b1da2c.png)
![Screenshot (165)](https://user-images.githubusercontent.com/39501945/77751161-2b53ed00-704b-11ea-9cd7-e7fc0b5acf01.png)
![Screenshot (164)](https://user-images.githubusercontent.com/39501945/77751164-2db64700-704b-11ea-815a-9b2f18a0a171.png)
![Screenshot (167)](https://user-images.githubusercontent.com/39501945/77751218-458dcb00-704b-11ea-95ce-8e5fd231eac6.png)
